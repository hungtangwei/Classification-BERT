{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "Gender_Classifiction_Bert.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qmrciH5KsbkC",
        "colab_type": "text"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/hungtangwei/Classification-BERT/blob/master/Gender_Classifiction_Bert.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xUMwx2ZpncD0",
        "colab_type": "text"
      },
      "source": [
        "#Authorship Profiling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DlG-ua3TncD1",
        "colab_type": "text"
      },
      "source": [
        "## Table of Contents\n",
        "\n",
        "* [Introduction](#sec_1)\n",
        "\n",
        "* [Data Preparation](#sec_2)\n",
        "    * [Step 01. Extract the twitter and userID](#sec_2_1)\n",
        "    * [Step 02. Feature extraction](#sec_2_2)\n",
        "* [Train the BERT Classification Model](#sec_3)\n",
        "    * [Load pretrained BERT model](#sec_3_1)\n",
        "    * [Set the AdamW optimizer & learning rate scheduler](#sec_3_2)\n",
        "    * [Training and Evalution](#sec_3_3)\n",
        "* [Test BERT Classification Model](#sec_4)\n",
        "    * [Prepare the test data for BERT classification model](#sec_4_1)\n",
        "    * [Get the prediction on test data set](#sec_4_2)\n",
        "    * [Get the final gender prediction](#sec_4_3)\n",
        "    * [Evaluation the accuracy of test data](#sec_4_4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_F0SlqACncD2",
        "colab_type": "text"
      },
      "source": [
        "## 1. Introduction <a class=\"anchor\" id=\"sec_1\"></a>\n",
        "\n",
        "In this task, we will develop a BERT classification model that can identify the gender of the tweet's author as accurate as possible.\n",
        "\n",
        "Here are some steps that we build the BERT classification model and then we will evaluation the accuracy of the test data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DhpB3HiTncD2",
        "colab_type": "text"
      },
      "source": [
        "## 2. Data preparation<a class=\"anchor\" id=\"sec_2\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NWQiibfYncD3",
        "colab_type": "text"
      },
      "source": [
        "### Step 01: Extract the twitters and user ID from data.zip<a class=\"anchor\" id=\"sec_2_1\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kaf8xc4MncD4",
        "colab_type": "text"
      },
      "source": [
        "<div class=\"alert alert-block alert-warning\">\n",
        "   Eextract the files from data.zip:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eZpN25xhncD4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# extract the files from data.zip\n",
        "import zipfile\n",
        "with zipfile.ZipFile(\"data.zip\",\"r\") as zip_ref:\n",
        "    zip_ref.extractall(\"targetdir\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OQ0iMuZNncD8",
        "colab_type": "text"
      },
      "source": [
        "<div class=\"alert alert-block alert-warning\">\n",
        "   Road the files:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1VCZZ4_tncD8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# get the user id from the file's name\n",
        "from os import listdir\n",
        "from os.path import isfile, isdir, join\n",
        "\n",
        "mypath = \"./targetdir/data\"\n",
        "files = listdir(mypath)\n",
        "if '.DS_Store' in files:\n",
        "    files.remove('.DS_Store')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CAn81aosncD_",
        "colab_type": "text"
      },
      "source": [
        "<div class=\"alert alert-block alert-warning\">\n",
        "   Extract the user ID from the file's name and extract the twitters from each html file:\n",
        "    \n",
        "    Caution: \n",
        "    \n",
        "    1. In here, each user ID have 100 twitters records.Therefore, if there are 3500 users, it will be 3500000 records in this data set.\n",
        "    \n",
        "    2. Remove the hashtage, usernames, number, punctuation, and emoji in twitter comment."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qAbfAYncncEA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# pip install git+https://github.com/erikavaris/tokenizer.git\n",
        "import xml.etree.ElementTree as ET\n",
        "import re\n",
        "import string \n",
        "from tokenizer import tokenizer\n",
        "T = tokenizer.TweetTokenizer(regularize=True,preserve_handles=False, preserve_hashes=False, preserve_case=False, preserve_url=False)\n",
        "\n",
        "\n",
        "ID=[]\n",
        "comment=[]\n",
        "language=[]\n",
        "for file in files:\n",
        "    name = file\n",
        "    name = re.sub(r'.xml', '', name)\n",
        "    document='./targetdir/data/'+file\n",
        "    tree = ET.parse(document) \n",
        "    root = tree.getroot()\n",
        "    for i in range(len(root)):\n",
        "        for j in range(0,100):\n",
        "            text = root[i][j].text\n",
        "            text = text.lower()\n",
        "            words = T.tokenize(text)\n",
        "            sentence=' '.join(words)\n",
        "            sentence = re.sub(r'\\[.*?\\]', '', sentence)\n",
        "            sentence = re.sub(r'[%s]' % re.escape(string.punctuation), '', sentence)\n",
        "            sentence = re.sub(r'\\w*\\d\\w*', '', sentence)\n",
        "            sentence = re.sub(r'\\â€¦', '', sentence)\n",
        "            comment.append(sentence)\n",
        "            ID.append(name)\n",
        "    for elem in tree.iter(tag='author'):\n",
        "        for j in range(0,100):\n",
        "            language.append(elem.attrib['lang'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zQ2fcu-incED",
        "colab_type": "text"
      },
      "source": [
        "<div class=\"alert alert-block alert-warning\">\n",
        "   Get the gender from train_labels.csv and combine with the twitters comment and user id and then create the new train and test data set:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mnpNfl-IncED",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "df = pd.DataFrame({'id': ID,\\\n",
        "                   'comment':comment,\\\n",
        "                   'language':language})\n",
        "\n",
        "train_labels=pd.read_csv('train_labels.csv')\n",
        "test=pd.read_csv('test.csv')\n",
        "\n",
        "# combine the twitter comments with id and gender\n",
        "train_df=pd.merge(train_labels,df, on='id',how='left')\n",
        "test_final=pd.merge(test,df, on='id',how='left')\n",
        "\n",
        "test_final=test_final.rename(columns={\"language_x\": \"language\"})\n",
        "test_final=test_final.drop(columns=['language_y'])\n",
        "test_final = test_final[['id','comment','gender','language']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "roW-vssvncEG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define the get_gender function to conver the gender to 0(femal) or 1(male)\n",
        "def get_gender(gender):\n",
        "    if gender =='female':\n",
        "        return 0\n",
        "    elif gender =='male':\n",
        "        return 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_MrSvEGjncEJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# convert the gender to 0(femal) or 1(male)\n",
        "train_df['label']=train_df.apply(lambda x: get_gender(x.gender),axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D9qevQPWncEM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# save the train and test into csv file\n",
        "train_df.to_csv(\"train_final.csv\",index=False)\n",
        "test_final.to_csv(\"test_final.csv\",index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UGuODAJ3ncEO",
        "colab_type": "text"
      },
      "source": [
        "### Step 02: Feature extraction<a class=\"anchor\" id=\"sec_2_2\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OHtQTdxWncEP",
        "colab_type": "text"
      },
      "source": [
        "<div class=\"alert alert-block alert-warning\">\n",
        "   Check the GPU environment and set up the environment:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_eXNgxccncEP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!pip install tensorflow\n",
        "import tensorflow as tf\n",
        "\n",
        "# get the name of gpu\n",
        "device_name = tf.test.gpu_device_name()\n",
        "\n",
        "if device_name == '/device:GPU:0':\n",
        "    print('Found GPU at: {}'.format(device_name))\n",
        "else:\n",
        "    raise SystemError('GPU device not found')\n",
        "    \n",
        "import torch\n",
        "\n",
        "# if Gpu is available, use the GPU\n",
        "if torch.cuda.is_available():        \n",
        "    device = torch.device(\"cuda\")\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# if not, print 'No GPU available'\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kwz04XxTncES",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Installing the Hugging Face Library\n",
        "\n",
        "#!pip3 install transformers==2.4.1\n",
        "import transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "922c-zaQncEU",
        "colab_type": "text"
      },
      "source": [
        "<div class=\"alert alert-block alert-warning\">\n",
        "   Load the train data set:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7bfmU5srncEW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "from transformers import BertTokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "df = pd.read_csv(\"train_final.csv\")\n",
        "\n",
        "sentences = df.comment.values\n",
        "labels = df.label.values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DsOVgq3EncEc",
        "colab_type": "text"
      },
      "source": [
        "<div class=\"alert alert-block alert-warning\">\n",
        "    Tokenization & Input Formatting:\n",
        "    \n",
        "    In this step, we tokenize all the sentence and map the tokens to their word IDs.\n",
        "    \n",
        "    1. Tokenize the sentence.\n",
        "    \n",
        "    2. Prepend the [CLS] token to the start.\n",
        "    \n",
        "    3. Append the [SEP] token to the end.\n",
        "    \n",
        "    3. Map tokens to their IDs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4KCIlc7QncEd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_ids = []\n",
        "\n",
        "#for loop for every sentence\n",
        "for sent in sentences:\n",
        "    # encode the sentence and add [CLS] and [SEP]\n",
        "    encoded_sent = tokenizer.encode(str(sent), add_special_tokens = True)\n",
        "    \n",
        "    # add the encoded_sent to input_ids list.\n",
        "    input_ids.append(encoded_sent)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QqXybPCtncEf",
        "colab_type": "text"
      },
      "source": [
        "<div class=\"alert alert-block alert-warning\">\n",
        "    Padding & Truncating:\n",
        "    \n",
        "    Make the sequences all have the same length by padding and truncating them"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dKBHreA9ncEf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# set the max length of sequence\n",
        "MAX_LEN = 128\n",
        "\n",
        "# pad our input tokens with value 0.\n",
        "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", value=0, truncating=\"post\", padding=\"post\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8T2ZySnancEh",
        "colab_type": "text"
      },
      "source": [
        "<div class=\"alert alert-block alert-warning\">\n",
        "    Attention Masks:\n",
        "    \n",
        "    The attention mask simply makes it explicit which tokens are actual words versus which are padding.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AeNPTharncEi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# set list of attention masks\n",
        "attention_masks = []\n",
        "\n",
        "# for loop for each sentence\n",
        "for sent in input_ids:\n",
        "    # if token ID is 0, set the mask to 0, others set the mask to 1\n",
        "    att_mask = [int(token_id > 0) for token_id in sent]\n",
        "    \n",
        "    # append attention mask to attention_masks list\n",
        "    attention_masks.append(att_mask)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lQESLeL_ncEl",
        "colab_type": "text"
      },
      "source": [
        "<div class=\"alert alert-block alert-warning\">\n",
        "    Split the data to training and validation data set and convert the dat into PyTorch data types:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XDLLhyaYncEm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Split the dataset into train and validation data set\n",
        "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids, labels, \n",
        "                                                            random_state=525, test_size=0.01)\n",
        "train_masks, validation_masks, _, _ = train_test_split(attention_masks, labels,\n",
        "                                             random_state=525, test_size=0.01)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oyRKYYyLncEp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert all inputs and labels into torch tensors\n",
        "train_inputs = torch.tensor(train_inputs)\n",
        "validation_inputs = torch.tensor(validation_inputs)\n",
        "\n",
        "train_labels = torch.tensor(train_labels)\n",
        "validation_labels = torch.tensor(validation_labels)\n",
        "\n",
        "train_masks = torch.tensor(train_masks)\n",
        "validation_masks = torch.tensor(validation_masks)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FUFcMl_TncEr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#create an iterator for our dataset \n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# set the batch_size as 32\n",
        "batch_size = 32\n",
        "\n",
        "# Create the DataLoader for our training set.\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "# Create the DataLoader for our validation set.\n",
        "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
        "validation_sampler = SequentialSampler(validation_data)\n",
        "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U-3mcOTBncEt",
        "colab_type": "text"
      },
      "source": [
        "## 3. Train the BERT Classification Model<a class=\"anchor\" id=\"sec_3\"></a>\n",
        "\n",
        "In here, we will fine tune the pre-trained BERT model to give outputs for our classification task."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3eZ-JWZIncEu",
        "colab_type": "text"
      },
      "source": [
        "<div class=\"alert alert-block alert-warning\"><a class=\"anchor\" id=\"sec_3_1\"></a>\n",
        "    Load pretrained BERT model of BertForSequenceClassification:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vn_arOQ1ncEu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from ipywidgets import IntProgress\n",
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "\n",
        "# load the pretrained BERT model of BertForSequenceClassification\n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-uncased\", \n",
        "    num_labels = 2,   \n",
        "    output_attentions = False, \n",
        "    output_hidden_states = False, \n",
        ").cuda() #use GPU"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JP2Jc2LwncEw",
        "colab_type": "text"
      },
      "source": [
        "<div class=\"alert alert-block alert-warning\"><a class=\"anchor\" id=\"sec_3_2\"></a>\n",
        "    Set the AdamW optimizer & learning rate scheduler:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5FQAB_EpncEx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create the AdamW optimizer\n",
        "optimizer = AdamW(model.parameters(),lr = 2e-5,eps = 1e-8 )\n",
        "\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "# Set the number of epochs\n",
        "epochs = 4\n",
        "\n",
        "# Set the total steps which is the number of batches * number of epochs\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps = 0,num_training_steps = total_steps)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7bUwVTzjncEz",
        "colab_type": "text"
      },
      "source": [
        "<div class=\"alert alert-block alert-warning\"><a class=\"anchor\" id=\"sec_3_3\"></a>\n",
        "    Training and Evalution:\n",
        "    \n",
        "    In training:\n",
        "    \n",
        "    1. Unpack our data inputs and labels\n",
        "    \n",
        "    2. Load data onto the GPU for acceleration\n",
        "    \n",
        "    3. Clear any previously calculated gradients out.\n",
        "    \n",
        "    4. Perform a forward pass \n",
        "    \n",
        "    5. Perform a backward pass to calculate the gradients\n",
        "    \n",
        "    6. Update parameters\n",
        "    \n",
        "    7. Track variables for monitoring progress\n",
        "    \n",
        "    \n",
        "    In Evaluation:\n",
        "    \n",
        "    1. Unpack our data inputs and labels\n",
        "    \n",
        "    2. Load data onto the GPU for acceleration\n",
        "    \n",
        "    3. Perform a forward pass \n",
        "    \n",
        "    4. Compute loss on validation data and track variables for monitoring progress"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZiIVdQfvncEz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# define the flat_accuracy function to calculate the accuracy of predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88zZSjiVncE2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "# Define the format_time function to calculate the spending time\n",
        "def format_time(elapsed):\n",
        "\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FwFGE5FCncE4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "\n",
        "# set the seed value to make the result repoducible\n",
        "seed_val = 25\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "# create the loss_values to store the average loss\n",
        "loss_values = []\n",
        "\n",
        "# for loop for each epochs\n",
        "for epoch_i in range(0, epochs):\n",
        "    \n",
        "    # The training step:   \n",
        "    print(\"\")\n",
        "    print('======= Epoch {:} / {:} ======='.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # set t0 to get the time\n",
        "    t0 = time.time()\n",
        "    # reset the total loss as zero\n",
        "    total_loss = 0\n",
        "\n",
        "    # set the model into training mode\n",
        "    model.train()\n",
        "\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "        # unpack data inputs, masks, and labels onto the GPU for acceleration\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        # clear any previously calculated gradients out.\n",
        "        model.zero_grad()        \n",
        "        # Perform a forward pass (it will return the loss)\n",
        "        outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels) \n",
        "        # get the loss value\n",
        "        loss = outputs[0]\n",
        "        # accumulate the training loss\n",
        "        total_loss += loss.item()\n",
        "        # perform a backward pass to calculate the gradients.\n",
        "        loss.backward()\n",
        "        # Clip the norm of the gradients to 1.0.\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # update parameters\n",
        "        optimizer.step()\n",
        "        # update the learning rate.\n",
        "        scheduler.step()\n",
        "\n",
        "    # calculate the average loss\n",
        "    avg_train_loss = total_loss / len(train_dataloader)            \n",
        "    # append the average loss to loss_values list.\n",
        "    loss_values.append(avg_train_loss)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))\n",
        "        \n",
        "    \n",
        "    \n",
        "    \n",
        "    # The Evalution step:\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # set the model into evalution mode.\n",
        "    model.eval()\n",
        "\n",
        "    # set the tracking variables \n",
        "    eval_loss, eval_accuracy = 0, 0\n",
        "    nb_eval_steps, nb_eval_examples = 0, 0\n",
        "\n",
        "    for batch in validation_dataloader:        \n",
        "        # add batch onto GPU\n",
        "        batch = tuple(t.to(device) for t in batch)        \n",
        "        # unpack data inputs, masks, and labels\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "        \n",
        "        # no gradients are calculated\n",
        "        with torch.no_grad():        \n",
        "            # Perform a forward pass (it will return the logit predictions)\n",
        "            outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
        "        \n",
        "        # get the logit predictions\n",
        "        logits = outputs[0]\n",
        "\n",
        "        # move the logits predictions and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "        \n",
        "        # calculate the accuracy \n",
        "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
        "        \n",
        "        # accumulate the total accuracy.\n",
        "        eval_accuracy += tmp_eval_accuracy\n",
        "\n",
        "        # track the number of batches\n",
        "        nb_eval_steps += 1\n",
        "\n",
        "    print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
        "    print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RMa-fxSWncE7",
        "colab_type": "text"
      },
      "source": [
        "## 4. Test BERT Classification Model<a class=\"anchor\" id=\"sec_4\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tmhnZOZdncE7",
        "colab_type": "text"
      },
      "source": [
        "<div class=\"alert alert-block alert-warning\"><a class=\"anchor\" id=\"sec_4_1\"></a>\n",
        "    Prepare the test data for BERT classification model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HpbhnluTncE7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# read the test data.\n",
        "df = pd.read_csv(\"test_final.csv\")\n",
        "\n",
        "# get the sentences from test data\n",
        "sentences = df.comment.values\n",
        "\n",
        "# tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "\n",
        "for sent in sentences:\n",
        "    # encode the sentence and add [CLS] and [SEP]\n",
        "    encoded_sent = tokenizer.encode(str(sent), add_special_tokens = True,)\n",
        "    # append the encoded_set to input_ids list\n",
        "    input_ids.append(encoded_sent)\n",
        "    \n",
        "# pad our input tokens\n",
        "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
        "\n",
        "# set list of attention masks\n",
        "attention_masks = []\n",
        "\n",
        "for seq in input_ids:\n",
        "    # if token ID is 0, set the mask to 0, others set the mask to 1\n",
        "    seq_mask = [float(i>0) for i in seq]\n",
        "    # append attention mask to attention_masks list\n",
        "    attention_masks.append(seq_mask) \n",
        "\n",
        "# Convert all inputs and masks into torch tensors\n",
        "prediction_inputs = torch.tensor(input_ids)\n",
        "prediction_masks = torch.tensor(attention_masks)\n",
        "\n",
        "\n",
        "# set the batch_size as 32 \n",
        "batch_size = 32  \n",
        "\n",
        "# Create the DataLoader for our test data set.\n",
        "prediction_data = TensorDataset(prediction_inputs, prediction_masks)\n",
        "prediction_sampler = SequentialSampler(prediction_data)\n",
        "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QgcILTCyncE-",
        "colab_type": "text"
      },
      "source": [
        "<div class=\"alert alert-block alert-warning\"><a class=\"anchor\" id=\"sec_4_2\"></a>\n",
        "    Get the prediction on test data set:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jj6Wu6tvncE-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# set the model into the evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# set the predictions list \n",
        "predictions = []\n",
        "\n",
        "for batch in prediction_dataloader:\n",
        "    # add batch to GPU\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    # unpack data inputs, and masks\n",
        "    b_input_ids, b_input_mask = batch\n",
        "  \n",
        "    # no gradients are calculated\n",
        "    with torch.no_grad():\n",
        "        # Perform a forward pass (it will return the logit predictions)\n",
        "        outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
        "    \n",
        "    # get the logit predictions\n",
        "    logits = outputs[0]\n",
        "    # move the logits predictions to CPU\n",
        "    logits = logits.detach().cpu().numpy()\n",
        "  \n",
        "    # append the logits prediction to preictions list\n",
        "    predictions.append(logits)\n",
        "    \n",
        "# get the flat predictions\n",
        "flat_predictions = [item for sublist in predictions for item in sublist]\n",
        "flat_predictions = np.argmax(flat_predictions, axis=1).flatten()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wtxXBzW1ncFA",
        "colab_type": "text"
      },
      "source": [
        "<div class=\"alert alert-block alert-warning\"><a class=\"anchor\" id=\"sec_4_3\"></a>\n",
        "    Get the final gender prediction:\n",
        "    \n",
        "    In this step we will combine the 100 twitter prediction to one final gender prediction for each userID.\n",
        "    \n",
        "    For example, if the userID has 100 twitter comments, and the BERT classifiction model predict there are 70 comments are male in these 100 twitter comments, then we final consider this userID is male."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OvLYszuAncFB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define the final_gender_prediction to get the final prediction.\n",
        "def final_gender_prediction(labels):\n",
        "    if labels >=0.5:\n",
        "        return 1\n",
        "    elif labels<0.5:\n",
        "        return 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rFexEd7lncFD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ID=df['id'].values\n",
        "pred_df=pd.DataFrame({'id':ID,'flat_label':flat_predictions})\n",
        "pred_df=pred_df.groupby('id').mean()\n",
        "\n",
        "# use the final_gender_prediction function to get the prediction.\n",
        "pred_df['Pred_label']=pred_df.apply(lambda x: final_gender_prediction(x.flat_label),axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q6LPIGwIncFE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# read the original test data\n",
        "test = pd.read_csv(\"test.csv\")\n",
        "# drop the columns of gender and language\n",
        "test=test.drop(columns=['gender','language'])\n",
        "# merge the test dataframe and pred_df dataframe on id to final dataframe\n",
        "final=pd.merge(test,pred_df, on='id')\n",
        "# rename the columns\n",
        "final=final.rename(columns={\"Pred_label\": \"gender\"})\n",
        "#drop the column of flat_label\n",
        "final=final.drop(columns=['flat_label'])\n",
        "final=final[['id','gender']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k8MFsE12ncFI",
        "colab_type": "text"
      },
      "source": [
        "<div class=\"alert alert-block alert-warning\"><a class=\"anchor\" id=\"sec_4_4\"></a>\n",
        "    Evaluation the accuracy of test data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YdE_HvfbncFI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, confusion_matrix, matthews_corrcoef\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# read the test_labels.csv\n",
        "df_anwser=pd.read_csv('test_labels.csv')\n",
        "\n",
        "# change the label into 0(femal) or 1(male)\n",
        "df_anwser['label']=df_anwser.apply(lambda x: get_gender(x.gender),axis=1)\n",
        "\n",
        "# get the predict labels and test labels\n",
        "predict_labels = final.gender.tolist() \n",
        "test_labels = df_anwser.label.tolist() \n",
        "predict_label=np.asarray(predict_labels)\n",
        "test_label=np.asarray(test_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YTbOmDFVncFK",
        "colab_type": "code",
        "colab": {},
        "outputId": "0bbfe873-ae0c-4886-f223-67b8ad7fe46b"
      },
      "source": [
        "print(confusion_matrix(test_labels,predict_labels))\n",
        "recall=recall_score(test_labels,predict_labels,average='macro')\n",
        "precision=precision_score(test_labels,predict_labels,average='macro')\n",
        "f1score=f1_score(test_labels,predict_labels,average='macro')\n",
        "accuracy=accuracy_score(test_labels,predict_labels)\n",
        "matthews = matthews_corrcoef(test_labels,predict_labels) \n",
        "print('Accuracy: '+ str(accuracy))\n",
        "print('Macro Precision: '+ str(precision))\n",
        "print('Macro Recall: '+ str(recall))\n",
        "print('Macro F1 score:'+ str(f1score))\n",
        "print('MCC:'+ str(matthews))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[220  32]\n",
            " [ 58 190]]\n",
            "Accuracy: 0.82\n",
            "Macro Precision: 0.823611381165338\n",
            "Macro Recall: 0.8195724526369688\n",
            "Macro F1 score:0.8193496587715776\n",
            "MCC:0.6431711522767296\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KK2ZK4TIncFN",
        "colab_type": "text"
      },
      "source": [
        "<div class=\"alert alert-block alert-warning\">\n",
        "    Save the final reslut to pred labels.csv:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RdVtvdFPncFO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define the gender function to conver the label to femal or male\n",
        "def final_gender(label):\n",
        "    if label ==0:\n",
        "        gender='female'\n",
        "        return gender\n",
        "    elif label ==1:\n",
        "        gender='male'\n",
        "        return gender"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6GJqTZwcncFP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# change the gender into female or male\n",
        "final['label']=final.apply(lambda x: final_gender(x.gender),axis=1)\n",
        "final=final.drop(columns=['gender'])\n",
        "final=final.rename(columns={\"label\": \"gender\"})\n",
        "\n",
        "# ouput as csv file\n",
        "final.to_csv('pred_labels.csv',index=False)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}